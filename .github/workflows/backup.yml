name: Database Backup

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:

jobs:
  backup-database:
    name: Backup Production Database
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup MySQL Client
      run: |
        sudo apt-get update
        sudo apt-get install -y mysql-client

    - name: Create database backup
      env:
        DB_HOST: ${{ secrets.DB_HOST }}
        DB_NAME: ${{ secrets.DB_NAME }}
        DB_USER: ${{ secrets.DB_USER }}
        DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
      run: |
        BACKUP_FILE="joomla-backup-$(date +%Y%m%d-%H%M%S).sql"
        
        mysqldump --host=$DB_HOST \
                  --user=$DB_USER \
                  --password=$DB_PASSWORD \
                  --single-transaction \
                  --routines \
                  --triggers \
                  $DB_NAME > $BACKUP_FILE
        
        # Compress backup
        gzip $BACKUP_FILE
        
        echo "BACKUP_FILE=${BACKUP_FILE}.gz" >> $GITHUB_ENV

    - name: Upload backup to cloud storage
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        S3_BUCKET: ${{ secrets.S3_BACKUP_BUCKET }}
      run: |
        # Install AWS CLI
        pip install awscli
        
        # Upload to S3
        aws s3 cp $BACKUP_FILE s3://$S3_BUCKET/database-backups/
        
        # Clean up old backups (keep last 30 days)
        aws s3 ls s3://$S3_BUCKET/database-backups/ | \
        sort | head -n -30 | awk '{print $4}' | \
        xargs -I {} aws s3 rm s3://$S3_BUCKET/database-backups/{}

    - name: Notify backup status
      if: always()
      run: |
        if [ $? -eq 0 ]; then
          echo "✅ Database backup completed successfully"
        else
          echo "❌ Database backup failed"
        fi